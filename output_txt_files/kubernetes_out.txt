## Command: kubectl logs pods/sklearn-flask-app-pod -f
 #

 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 194-414-639
[2020-30-04 23:00:52,595] INFO in app: JSON payload: 
{'CHAS': {'0': 0}, 'RM': {'0': 6.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2019-08-09 01:51:52,627] INFO in app: Inference payload DataFrame: 
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2020-30-04 23:01:52,644] INFO in app: Scaling Payload: 
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2020-30-04 23:02:52,666] INFO in app: Output prediction: [20.35373177134412]
127.0.0.1 - - [30/Apr/2020 23:02:52] "POST /predict HTTP/1.1" 200 -

## Output from other terminal window.
# ./make_prediction.sh
#

Port: 8080
{
  "prediction": [
    20.35373177134412
  ]
}